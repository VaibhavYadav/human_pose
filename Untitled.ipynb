{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import LSPDataset, LSPExtendedDataset\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import torch.utils.data as data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from vis import show_pose, show_pose_from_hmap, show_hmap\n",
    "from models import PoseNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lspdata = LSPDataset('./dataset/lsp_dataset/', 'points')\n",
    "lspdata = LSPExtendedDataset('./dataset/lspet_dataset/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a, b, c = lspdata.__getitem__(np.random.randint(len(lspdata)))\n",
    "show_pose(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data.DataLoader(lspdata, 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSE_Loss(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(MSE_Loss, self).__init__()\n",
    "        \n",
    "    def forward(self, output, joints, mask):\n",
    "        mask = torch.cat((ignore_joints.unsqueeze(2), ignore_joints.unsqueeze(2)), axis=2).reshape((-1, 28))\n",
    "        return torch.sum(mask * (output - joints)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = PoseNet().cuda()\n",
    "net.load_state_dict(torch.load('./weights/simple_pose.weights'))\n",
    "criterion = MSE_Loss().cuda()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(50):\n",
    "    for batch, batch_data in enumerate(dataloader):\n",
    "        net.zero_grad()\n",
    "        im, joints, ignore_joints = batch_data\n",
    "        im = im.cuda()\n",
    "        joints = joints.cuda()\n",
    "        ignore_joints = ignore_joints.cuda()\n",
    "        output = net(im)\n",
    "        loss = criterion(output, joints, ignore_joints)\n",
    "        loss.backward() \n",
    "        optimizer.step()\n",
    "        if (batch+1) % 10 == 0:\n",
    "            print('Batch: {}, Loss: {}, Epoch: {}'.format(batch + 1, loss.data, epoch))\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('Saving weights for epoch: {}'.format(epoch))\n",
    "#         torch.save(net.state_dict(), './weights/simple_pose{}.weights'.format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(net.state_dict(), './weights/simple_pose.weights'.format(epoch))\n",
    "net.eval()\n",
    "a, _, c = lspdata.__getitem__(np.random.randint(len(lspdata)))\n",
    "b = net(a.unsqueeze(0).cuda())\n",
    "show_pose(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = './dataset/lsp_dataset/images/'\n",
    "# base_dir = './test/'\n",
    "t = transforms.Compose([\n",
    "            transforms.Resize((128, 128)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "test_image = os.listdir(base_dir)\n",
    "image = Image.open(base_dir + test_image[np.random.randint(len(test_image))])\n",
    "show_pose(t(image) ,net(t(image).unsqueeze(0).cuda()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lspdata = LSPDataset('./dataset/lsp_dataset/', 'points')\n",
    "lspdata = LSPExtendedDataset('./dataset/lspet_dataset/', 'heatmap')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, c = lspdata.__getitem__(np.random.randint(len(lspdata)))\n",
    "show_pose_from_hmap(a, b, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data.DataLoader(lspdata, 10, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JointsMSELoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(JointsMSELoss, self).__init__()\n",
    "        self.criterion = nn.MSELoss()\n",
    "\n",
    "    def forward(self, output, target, mask):\n",
    "        pred = output.reshape(10, 14, -1)\n",
    "        tar = target.reshape(10, 14, -1)\n",
    "#         mask = mask.reshape(10, 14)\n",
    "        loss = 0\n",
    "        for i in range(len(pred)):\n",
    "            loss +=  self.criterion(pred[i], tar[i])\n",
    "        print(loss.shape)\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "net = HeatmapPose().cuda()\n",
    "net.load_state_dict(torch.load('./heatmap_pose.weights'))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(net.parameters(), lr = 0.0000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(100):\n",
    "    for batch, batch_data in enumerate(dataloader):\n",
    "        net.zero_grad()\n",
    "        im, joints, _ = batch_data\n",
    "        im = im.cuda()\n",
    "        joints = joints.cuda()\n",
    "        output = net(im)\n",
    "        loss = criterion(output, joints)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch % 10 == 0:\n",
    "            print('Batch: {}, Loss: {}, Epoch: {}'.format(batch, loss.data, epoch))\n",
    "    torch.save(net.state_dict(), './heatmap_pose.weights')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a,c, m = lspdata.__getitem__(np.random.randint(len(lspdata)))\n",
    "h = net(a.unsqueeze(0).cuda()).squeeze().cpu().detach()\n",
    "show_hmap(a, h)\n",
    "show_pose_from_hmap(a, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a,d = lspdata.__getitem__(np.random.randint(len(lspdata)))\n",
    "a = c.unsqueeze(0)\n",
    "d = d.unsqueeze(0)\n",
    "criterion(a, d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "base_dir = './New folder/'\n",
    "# base_dir = './dataset/FLIC/images/' \n",
    "# base_dir = './dataset/lsp_dataset/images/'\n",
    "t = transforms.Compose([\n",
    "            transforms.Resize((256, 256)),\n",
    "            transforms.ToTensor(),\n",
    "        ])\n",
    "test_image = os.listdir(base_dir)\n",
    "image = Image.open(base_dir + test_image[np.random.randint(len(test_image))])\n",
    "image = t(image)\n",
    "h = net(image.unsqueeze(0).cuda()).squeeze().cpu().detach()\n",
    "show_pose_from_hmap(image, h)\n",
    "show_hmap(image, h)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeatmapPose(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HeatmapPose, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 128, 5, padding = 2)\n",
    "        self.conv2 = nn.Conv2d(128, 128, 5, padding = 2)\n",
    "        self.conv3 = nn.Conv2d(128, 128, 5, padding = 2)\n",
    "        self.conv33 = nn.Conv2d(128, 512, 9, padding = 4)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x -> [-1, 3, 256, 256]\n",
    "        x = F.relu(self.conv1(x))\n",
    "        # x -> [-1, 32, 256, 256]\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # x -> [-1, 32, 128, 128]\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        # x -> [-1, 32, 128, 128]\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # x -> [-1, 32, 64, 64]\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        # x -> [-1, 64, 64, 64]\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        # x -> [-1, 64, 32, 32]\n",
    "        x = F.relu(self.conv33(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "class HeatmapPoseA(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(HeatmapPoseA, self).__init__()\n",
    "        self.hmap_pose = HeatmapPose()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        a = self.hmap_pose(x)\n",
    "        x = F.interpolate(x, 64)\n",
    "        b = self.hmap_pose(x)\n",
    "        x = F.interpolate(x, 32)\n",
    "        c = self.hmap_pose(x)\n",
    "        x = torch.cat((a, b, c), axis=0)\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit ('pytorch': conda)",
   "language": "python",
   "name": "python38264bitpytorchcondaf04cb2303bb94659b54446e023c3cb62"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
